{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from Models import modelpool\n",
    "from Preprocess import datapool\n",
    "from torch import nn\n",
    "from spiking_layer_ours import SPIKE_layer\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from utils_my import add_dimension\n",
    "from utils_my import replace_maxpool2d_by_avgpool2d, replace_layer_by_tdlayer\n",
    "from slerp import slerp\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def isActivation(name):\n",
    "    if 'relu' in name.lower():\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def replace_activation_by_spike(model, thresholds, thresholds1, n_steps, counter=0):\n",
    "    thresholds_new = deepcopy(thresholds)\n",
    "    thresholds_new1 = deepcopy(thresholds1)\n",
    "    \n",
    "    for name, module in model._modules.items():\n",
    "        if hasattr(module,\"_modules\"):\n",
    "            model._modules[name], counter, thresholds_new = replace_activation_by_spike(module, thresholds_new, thresholds_new1, n_steps, counter)\n",
    "        if isActivation(module.__class__.__name__.lower()):\n",
    "            thresholds_new[counter, n_steps:] = thresholds_new1[counter, 1] / n_steps  # thresholds_out_sum/n_steps# thresholds1[counter,1] / n_steps\n",
    "            thresholds_new[counter, :n_steps] = thresholds_new1[counter, 0] / n_steps  # thresholds_inner_sum/n_steps#thresholds1[counter,0] / n_steps\n",
    "            model._modules[name] = SPIKE_layer(thresholds_new[counter, n_steps:], thresholds_new[counter, 0:n_steps])\n",
    "            counter += 1\n",
    "    return model, counter, thresholds_new\n",
    "\n",
    "\n",
    "def interpolate_state_dicts(state_dict_1, state_dict_2, weight,\n",
    "                            bias_norm=False, use_slerp=False):\n",
    "    if use_slerp:\n",
    "        model_state = deepcopy(state_dict_1)\n",
    "        for p_name in model_state:\n",
    "            if \"batches\" not in p_name:\n",
    "                model_state[p_name] = slerp(weight, state_dict_1[p_name], state_dict_2[p_name])\n",
    "        return model_state\n",
    "    elif bias_norm:\n",
    "        model_state = deepcopy(state_dict_1)\n",
    "        height = 0\n",
    "        for p_name in model_state:\n",
    "            if \"batches\" not in p_name:\n",
    "                model_state[p_name].zero_()\n",
    "                if \"weight\" in p_name:\n",
    "                    model_state[p_name].add_(1.0 - weight, state_dict_1[p_name])\n",
    "                    model_state[p_name].add_(weight, state_dict_2[p_name])\n",
    "                    height += 1\n",
    "                if \"bias\" in p_name:\n",
    "                    model_state[p_name].add_((1.0 - weight)**height, state_dict_1[p_name])\n",
    "                    model_state[p_name].add_(weight**height, state_dict_2[p_name])\n",
    "                if \"res_scale\" in p_name:\n",
    "                    model_state[p_name].add_(1.0 - weight, state_dict_1[p_name])\n",
    "                    model_state[p_name].add_(weight, state_dict_2[p_name])\n",
    "        return model_state\n",
    "    else:\n",
    "        return {key: (1 - weight) * state_dict_1[key] + \n",
    "                weight * state_dict_2[key] for key in state_dict_1.keys()}\n",
    "\n",
    "\n",
    "def interpolate_multi_state_dicts(sd_s, weight_s, use_slerp=False):\n",
    "    if use_slerp:\n",
    "        sd_interpolated = deepcopy(sd_s[0])\n",
    "        weight_interpolated = weight_s[0]\n",
    "        for i in range(1, len(sd_s)):\n",
    "            sd_next = sd_s[i]\n",
    "            weight_next = weight_s[i]\n",
    "            t = weight_next / (weight_interpolated + weight_next)\n",
    "            sd_interpolated = interpolate_state_dicts(sd_interpolated, sd_next, t, use_slerp=use_slerp)\n",
    "            weight_interpolated += weight_next\n",
    "        return sd_interpolated\n",
    "    else:\n",
    "        sd_interpolated = deepcopy(sd_s[0])\n",
    "        for key in sd_s[0].keys():\n",
    "            sd_interpolated[key] = weight_s[0] * sd_s[0][key]\n",
    "            for i in range(1, len(sd_s)):\n",
    "                sd_interpolated[key] += weight_s[i] * sd_s[i][key]\n",
    "        return sd_interpolated\n",
    "        \n",
    "        \n",
    "def validate_snn(model, loader, n_steps, device, verbose=1, use_double=False):\n",
    "    device_old = get_device(model)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for data, target in loader:\n",
    "        data = add_dimension(data, n_steps)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        if use_double:\n",
    "            data = data.double()\n",
    "        output = model(data, L=0, t=n_steps)\n",
    "        output = torch.mean(output, dim=1)\n",
    "        total += target.size(0)\n",
    "        correct += (output.argmax(1) == target).sum().item()\n",
    "    if verbose != 0:\n",
    "        print('Accuracy of the network on the test images: %f' % (100 * correct / total))\n",
    "    acc = 100 * correct / total\n",
    "    model.to(device_old)\n",
    "    return acc\n",
    "\n",
    "def validate_snn_ensemble(models, loader, n_steps, device, verbose=1):\n",
    "    device_old = get_device(models[0])\n",
    "    for model in models:\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for data, target in loader:\n",
    "        data = add_dimension(data, n_steps)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = torch.zeros(data.size(0), 10).to(device)\n",
    "        for model in models:\n",
    "            output += torch.mean(model(data, L=0, t=n_steps), dim=1)\n",
    "        total += target.size(0)\n",
    "        correct += (output.argmax(1) == target).sum().item()\n",
    "    if verbose != 0:\n",
    "        print('Accuracy of the network on the test images: %f' % (100 * correct / total))\n",
    "    acc = 100 * correct / total\n",
    "    for model in models:\n",
    "        model.to(device_old)\n",
    "    return acc\n",
    "    \n",
    "def validate_ann(model, loader, device, verbose=1, use_double=False):\n",
    "    device_old = get_device(model)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for data, target in loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        if use_double:\n",
    "            data = data.double()\n",
    "        output = model(data)\n",
    "        total += target.size(0)\n",
    "        correct += (output.argmax(1) == target).sum().item()\n",
    "    if verbose != 0:\n",
    "        print('Accuracy of the network on the test images: %f' % (100 * correct / total))\n",
    "    acc = 100 * correct / total\n",
    "    model.to(device_old)\n",
    "    return acc\n",
    "\n",
    "def ann_to_snn(model, thresholds, thresholds1, n_steps):\n",
    "    model, counter, thresholds_new = replace_activation_by_spike(model, thresholds, thresholds1, n_steps)\n",
    "    model = replace_maxpool2d_by_avgpool2d(model)\n",
    "    model = replace_layer_by_tdlayer(model)\n",
    "    return model, thresholds_new\n",
    "\n",
    "\n",
    "def bn_calibration_init(m):\n",
    "    \"\"\" calculating post-statistics of batch normalization \"\"\"\n",
    "    if getattr(m, 'track_running_stats', False):\n",
    "        # reset all values for post-statistics\n",
    "        m.reset_running_stats()\n",
    "        # set bn in training mode to update post-statistics\n",
    "        m.training = True\n",
    "        # use cumulative moving average\n",
    "        m.momentum = None\n",
    "\n",
    "def reset_bn_stats(model, device, bn_loader, n_steps, layerwise=False, ann=False, use_double=False):\n",
    "    # Reset batch norm statistics\n",
    "    model.to(device)\n",
    "    # get batchnorm layer names\n",
    "    bn_layer_names = [name for name, layer in model.named_modules() if isinstance(layer, (nn.BatchNorm2d))]\n",
    "    for m in model.modules():\n",
    "        bn_calibration_init(m)\n",
    "    model.train()\n",
    "    with torch.no_grad():\n",
    "        L_range = range(1, 14) if layerwise else [0]\n",
    "        for L in L_range:\n",
    "            for data, _ in bn_loader:\n",
    "                if not ann:\n",
    "                    data = add_dimension(data, n_steps)\n",
    "                data = data.to(device)\n",
    "                if use_double:\n",
    "                    data = data.double()\n",
    "                model(data, L=L, t=n_steps)\n",
    "            # set current bn layer in eval mode\n",
    "            if layerwise:\n",
    "                layer = dict(model.named_modules())[bn_layer_names[L-1]]\n",
    "                layer.eval()\n",
    "    model.eval()\n",
    "    model.to('cpu')\n",
    "\n",
    "def get_device(item):\n",
    "    if isinstance(item, nn.Module):\n",
    "        return next(item.parameters()).device\n",
    "    elif isinstance(item, OrderedDict):\n",
    "        return next(iter(item.values())).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "class args:\n",
    "    model = 'vgg16'\n",
    "    dataset = 'cifar10'\n",
    "    batch_size = 128\n",
    "    t = 1\n",
    "device = torch.device('cuda:1')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "n_steps = args.t\n",
    "train_loader, test_loader = datapool(args.dataset, args.batch_size, 0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v_idx_s = list(range(2, 16)) + list(range(22, 37))\n",
    "v_idx_s = list(range(2, 13))\n",
    "# v_idx_s = [2]\n",
    "num_models = len(v_idx_s) + 1\n",
    "\n",
    "model_s = [modelpool(args.model, args.dataset) for _ in range(num_models)]\n",
    "ckpt_model_idx = 3\n",
    "sd = torch.load(f'saved_models/cifar10_vgg16_{ckpt_model_idx}.pth', map_location='cpu', weights_only=True)\n",
    "for model in model_s:\n",
    "    model.load_state_dict(sd)\n",
    "\n",
    "num_relu = str(model_s[0]).count('ReLU')\n",
    "# prefix = 'cifar10_vgg16_3_lr_1e3/'\n",
    "prefix = ''\n",
    "thresholds = torch.zeros(num_relu, 2*n_steps)\n",
    "thresholds1 = torch.Tensor(np.load(f'{prefix}cifar10_vgg16_{ckpt_model_idx}_threshold_all_noaug{n_steps}.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_s = [ann_to_snn(model, thresholds, thresholds1, n_steps) for model in model_s]\n",
    "threshold_new = model_s[0][1]\n",
    "model_s = [pair[0] for pair in model_s]\n",
    "\n",
    "snn_init = modelpool(args.model, args.dataset)\n",
    "ann_sd = torch.load(f'saved_models/cifar10_vgg16_{ckpt_model_idx}.pth', map_location='cpu', weights_only=True)\n",
    "snn_init.load_state_dict(ann_sd)\n",
    "snn_init = ann_to_snn(snn_init, thresholds, thresholds1, n_steps)[0]\n",
    "\n",
    "ann_model = modelpool(args.model, args.dataset)\n",
    "ann_sd = torch.load(f'saved_models/cifar10_vgg16_{ckpt_model_idx}.pth', map_location='cpu', weights_only=True)\n",
    "ann_model.load_state_dict(ann_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_s = [ann_to_snn(model, thresholds, thresholds1, n_steps) for model in model_s]\n",
    "sd_s = [torch.load(f'{prefix}cifar10_vgg16_{ckpt_model_idx}_updated_snn1_1.pth', weights_only=True, map_location='cpu')] + \\\n",
    "        [torch.load(f'{prefix}cifar10_vgg16_{ckpt_model_idx}_updated_snn1_1_v{v}.pth', weights_only=True, map_location='cpu') for v in v_idx_s]\n",
    "for model, sd in zip(model_s, sd_s):\n",
    "    model.load_state_dict(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 92.370000\n",
      "Accuracy of the network on the test images: 92.430000\n",
      "Accuracy of the network on the test images: 92.370000\n",
      "Accuracy of the network on the test images: 92.450000\n",
      "Accuracy of the network on the test images: 92.300000\n",
      "Accuracy of the network on the test images: 92.420000\n",
      "Accuracy of the network on the test images: 92.720000\n",
      "Accuracy of the network on the test images: 92.570000\n",
      "Accuracy of the network on the test images: 92.370000\n",
      "Accuracy of the network on the test images: 92.570000\n",
      "Accuracy of the network on the test images: 92.380000\n",
      "Accuracy of the network on the test images: 92.690000\n",
      "Accuracy of the network on the test images: 94.320000\n",
      "[92.37, 92.43, 92.37, 92.45, 92.3, 92.42, 92.72, 92.57, 92.37, 92.57, 92.38, 92.69] 94.32\n"
     ]
    }
   ],
   "source": [
    "acc_s = [validate_snn(model, test_loader, n_steps, device, use_double=False) for model in model_s]\n",
    "acc_ensemble = validate_snn_ensemble(model_s, test_loader, n_steps, device)\n",
    "print(acc_s, acc_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test PFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PFM_outputs(model_merge_s, model_merged, data, L, n_steps):\n",
    "    outputs_s = [model(data, L=L, t=n_steps) for model in model_merge_s]\n",
    "    outputs_avg = torch.zeros_like(outputs_s[0])\n",
    "    for outputs in outputs_s:\n",
    "        outputs_avg += outputs\n",
    "    outputs_avg /= len(outputs_s)\n",
    "    outputs = model_merged(outputs_avg, L=0, t=n_steps, prev_L=L).mean(1)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 92.380000\n",
      "Accuracy of the network on the test images: 93.970000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "93.97"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_merge_s = [deepcopy(model_s[i]) for i in [-3, 1, 3]]\n",
    "num_merge_models = len(model_merge_s)\n",
    "model_merge_mid = deepcopy(model_s[0])\n",
    "sd_merge_mid = interpolate_multi_state_dicts([model.state_dict() for model in model_merge_s], [1/num_merge_models]*num_merge_models)\n",
    "model_merge_mid.load_state_dict(sd_merge_mid)\n",
    "\n",
    "for model_merge in model_merge_s:\n",
    "    model_merge.to(device)\n",
    "    model_merge.eval()\n",
    "model_merge_mid.to(device)\n",
    "model_merge_mid.eval()\n",
    "\n",
    "validate_snn(model_merge_mid, test_loader, n_steps, device)\n",
    "validate_snn_ensemble(model_merge_s, test_loader, n_steps, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 92.590000 , L=1\n",
      "Accuracy of the network on the test images: 92.990000 , L=2\n",
      "Accuracy of the network on the test images: 92.850000 , L=3\n",
      "Accuracy of the network on the test images: 93.030000 , L=4\n",
      "Accuracy of the network on the test images: 93.220000 , L=5\n",
      "Accuracy of the network on the test images: 93.590000 , L=6\n",
      "Accuracy of the network on the test images: 93.750000 , L=7\n",
      "Accuracy of the network on the test images: 94.200000 , L=8\n",
      "Accuracy of the network on the test images: 93.930000 , L=9\n",
      "Accuracy of the network on the test images: 94.090000 , L=10\n",
      "Accuracy of the network on the test images: 93.980000 , L=11\n",
      "Accuracy of the network on the test images: 93.990000 , L=12\n",
      "Accuracy of the network on the test images: 94.030000 , L=13\n",
      "Accuracy of the network on the test images: 94.030000 , L=14\n",
      "Accuracy of the network on the test images: 93.960000 , L=15\n",
      "Accuracy of the network on the test images: 93.970000 , L=16\n"
     ]
    }
   ],
   "source": [
    "cur_test_loader = test_loader\n",
    "for L in range(1, 17):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for data, target in cur_test_loader:\n",
    "        data = add_dimension(data, n_steps)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        outputs = PFM_outputs(model_merge_s, model_merge_mid, data, L, n_steps)\n",
    "        total += target.size(0)\n",
    "        correct += (outputs.argmax(1) == target).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the test images: %f' % (100 * correct / total), f\", L={L}\")\n",
    "    acc = 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 92.850000 , L=3\n"
     ]
    }
   ],
   "source": [
    "L = 3\n",
    "total = 0\n",
    "correct = 0\n",
    "for data, target in test_loader:\n",
    "    data = add_dimension(data, n_steps)\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    outputs = PFM_outputs(model_merge_s, model_merge_mid, data, L, n_steps)\n",
    "    total += target.size(0)\n",
    "    correct += (outputs.argmax(1) == target).sum().item()\n",
    "print('Accuracy of the network on the test images: %f' % (100 * correct / total), f\", L={L}\")\n",
    "acc = 100 * correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Try to improve merging on L = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.37, 92.43, 92.37, 92.45, 92.3, 92.42, 92.72, 92.57, 92.37, 92.57, 92.38, 92.69]\n"
     ]
    }
   ],
   "source": [
    "print(acc_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 92.340000\n",
      "Accuracy of the network on the test images: 93.380000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "93.38"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_merge_s = [deepcopy(model_s[i]) for i in [0, 1]]\n",
    "num_merge_models = len(model_merge_s)\n",
    "model_merge_mid = deepcopy(model_s[0])\n",
    "sd_merge_mid = interpolate_multi_state_dicts([model.state_dict() for model in model_merge_s], [1/num_merge_models]*num_merge_models)\n",
    "model_merge_mid.load_state_dict(sd_merge_mid)\n",
    "\n",
    "for model_merge in model_merge_s:\n",
    "    model_merge.to(device)\n",
    "    model_merge.eval()\n",
    "model_merge_mid.to(device)\n",
    "model_merge_mid.eval()\n",
    "\n",
    "validate_snn(model_merge_mid, test_loader, n_steps, device)\n",
    "validate_snn_ensemble(model_merge_s, test_loader, n_steps, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, _ = next(iter(test_loader))\n",
    "data = add_dimension(data, n_steps)\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pre activation difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 1\n",
    "outputs_s = [model.layer1[:2](data).mean(1) for model in model_merge_s]\n",
    "outputs_avg = torch.zeros_like(outputs_s[0])\n",
    "with torch.no_grad():\n",
    "    for outputs in outputs_s:\n",
    "        outputs_avg += outputs\n",
    "    outputs_avg /= len(outputs_s)\n",
    "    outputs_mid = model_merge_mid.layer1[:2](data).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0757, device='cuda:1')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(outputs_mid[0] - outputs_avg[0]).abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2019, 0.1009],\n",
       "        [0.1956, 0.0978],\n",
       "        [0.1320, 0.0660],\n",
       "        [0.1984, 0.0992],\n",
       "        [0.1295, 0.0647],\n",
       "        [0.1269, 0.0634],\n",
       "        [0.1491, 0.0745],\n",
       "        [0.0798, 0.0399],\n",
       "        [0.0590, 0.0295],\n",
       "        [0.0704, 0.0352],\n",
       "        [0.0393, 0.0197],\n",
       "        [0.0481, 0.0241],\n",
       "        [0.2805, 0.1402],\n",
       "        [0.0458, 0.0229],\n",
       "        [0.0836, 0.0418]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0757, 0.0724, 0.0698,  ..., 0.0000, 0.0000, 0.0000], device='cuda:1')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = (outputs_mid[0] - outputs_avg[0]).abs().flatten()\n",
    "# sort by descending order\n",
    "diff, indices = diff.sort(descending=True)\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([65536])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'threshold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[158], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m threshold\n",
      "\u001b[0;31mNameError\u001b[0m: name 'threshold' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0144, device='cuda:1')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 1\n",
    "outputs_s = [model(data, L=L, t=n_steps).mean(1) for model in model_merge_s]\n",
    "outputs_avg = torch.zeros_like(outputs_s[0])\n",
    "with torch.no_grad():\n",
    "    for outputs in outputs_s:\n",
    "        outputs_avg += outputs\n",
    "    outputs_avg /= len(outputs_s)\n",
    "    outputs_mid = model_merge_mid(data, L=L, t=n_steps).mean(1)\n",
    "nonzero_mask = (outputs_avg != 0) | (outputs_mid != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = (outputs_avg[nonzero_mask] - outputs_mid[nonzero_mask]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = diff[diff!=0]\n",
    "# plot the cdf of the difference\n",
    "plt.hist(diff.cpu().numpy(), bins=100, cumulative=True, density=True, histtype='step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abs_diff: 0.0007899306365288794, max_diff: 0.20188574492931366, scale_avg (754814115): 0.1837773323059082, scale_mid (670974811): 0.20188568532466888, L=1\n",
      "abs_diff: 0.0008815779001452029, max_diff: 0.19557975232601166, scale_avg (592921508): 0.1721639782190323, scale_mid (523387731): 0.19557981193065643, L=2\n",
      "abs_diff: 0.0005983338924124837, max_diff: 0.13197259604930878, scale_avg (443334791): 0.1090385913848877, scale_mid (359660086): 0.1319725662469864, L=3\n",
      "abs_diff: 0.0009561455808579922, max_diff: 0.19841402769088745, scale_avg (162789967): 0.15083763003349304, scale_mid (123600573): 0.19841410219669342, L=4\n",
      "abs_diff: 0.0006224726093932986, max_diff: 0.12946902215480804, scale_avg (128215390): 0.09683099389076233, scale_mid (94190887): 0.12946906685829163, L=5\n",
      "abs_diff: 0.0006244082469493151, max_diff: 0.12687665224075317, scale_avg (95757875): 0.09000459313392639, scale_mid (67899902): 0.12687665224075317, L=6\n",
      "abs_diff: 0.0007428361568599939, max_diff: 0.14906498789787292, scale_avg (60054422): 0.10190467536449432, scale_mid (41022302): 0.14906498789787292, L=7\n",
      "abs_diff: 0.0003908751823473722, max_diff: 0.07979712635278702, scale_avg (41785003): 0.05514555051922798, scale_mid (28405448): 0.07979714870452881, L=8\n",
      "abs_diff: 0.00028746743919327855, max_diff: 0.058995846658945084, scale_avg (42092016): 0.04217735677957535, scale_mid (29840578): 0.05899585783481598, L=9\n",
      "abs_diff: 0.00034247804433107376, max_diff: 0.07041503489017487, scale_avg (48642508): 0.055462367832660675, scale_mid (38535831): 0.07041499763727188, L=10\n",
      "abs_diff: 0.00018397947133053094, max_diff: 0.03931347280740738, scale_avg (51340985): 0.033887848258018494, scale_mid (44177924): 0.03931347280740738, L=11\n",
      "abs_diff: 0.0002235744468634948, max_diff: 0.04810955747961998, scale_avg (47952196): 0.04083073511719704, scale_mid (40085843): 0.04810952767729759, L=12\n",
      "abs_diff: 0.0013776113046333194, max_diff: 0.2804771661758423, scale_avg (33893371): 0.2417718470096588, scale_mid (28813373): 0.28047728538513184, L=13\n",
      "abs_diff: 0.00022286176681518555, max_diff: 0.045754674822092056, scale_avg (67008808): 0.040639251470565796, scale_mid (58718743): 0.04575466737151146, L=14\n",
      "abs_diff: 0.00040891641401685774, max_diff: 0.0835646241903305, scale_avg (59694505): 0.07610636204481125, scale_mid (53735400): 0.08356460183858871, L=15\n",
      "abs_diff: 0.002158602699637413, max_diff: 5.704255104064941, scale_avg (500000): 1.3839242458343506, scale_mid (500000): 1.4030622243881226, L=16\n"
     ]
    }
   ],
   "source": [
    "abs_diff_s = []\n",
    "max_diff_s = []\n",
    "scale_avg_s = []\n",
    "scale_mid_s = []\n",
    "mse_loss = nn.MSELoss()\n",
    "\n",
    "for L in range(1, 17):\n",
    "    # L = 1\n",
    "    total = 0\n",
    "    nonzero_avg = 0\n",
    "    nonzero_mid = 0\n",
    "    abs_diff = 0\n",
    "    max_diff = 0\n",
    "    scale_avg = 0\n",
    "    scale_mid = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in train_loader:\n",
    "            data = add_dimension(data, n_steps)\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs_avg = None\n",
    "            for model_merge in model_merge_s:\n",
    "                outputs = model_merge(data, L=L, t=n_steps).mean(1)\n",
    "                if outputs_avg is None:\n",
    "                    outputs_avg = outputs\n",
    "                else:\n",
    "                    outputs_avg += outputs\n",
    "            outputs_avg /= len(outputs_s)\n",
    "            outputs_mid = model_merge_mid(data, L=L, t=n_steps).mean(1)\n",
    "            # post_act_loss += criterion(outputs_mid, outputs_avg) * target.size(0)\n",
    "            neq_num = (outputs_mid != outputs_avg).sum()\n",
    "            abs_diff += (outputs_mid - outputs_avg).abs().sum() / neq_num\n",
    "            batch_max_diff = (outputs_mid - outputs_avg).abs().max()\n",
    "            # calculate average scale of nonzero outputs\n",
    "            scale_avg += outputs_avg[outputs_avg != 0].abs().sum()\n",
    "            scale_mid += outputs_mid[outputs_mid != 0].abs().sum()\n",
    "            max_diff = max(max_diff, batch_max_diff)\n",
    "            total += target.size(0)\n",
    "            nonzero_avg += (outputs_avg != 0).sum()\n",
    "            nonzero_mid += (outputs_mid != 0).sum()\n",
    "        abs_diff = abs_diff / total\n",
    "        scale_avg = scale_avg / nonzero_avg\n",
    "        scale_mid = scale_mid / nonzero_mid\n",
    "        abs_diff_s.append(abs_diff)\n",
    "        max_diff_s.append(max_diff)\n",
    "        scale_avg_s.append(scale_avg)\n",
    "        scale_mid_s.append(scale_mid)\n",
    "        print(f\"abs_diff: {abs_diff}, max_diff: {max_diff}, scale_avg ({nonzero_avg}): {scale_avg}, scale_mid ({nonzero_mid}): {scale_mid}, L={L}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distill the pre-activation in the first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 92.340000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "92.34"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model_merge_mid = deepcopy(model_merge_mid)\n",
    "train_model_merge_mid.to(device)\n",
    "validate_snn(train_model_merge_mid, test_loader, n_steps, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(train_model_merge_mid.parameters(), lr=4e-5, weight_decay=5e-4)\n",
    "# only train the first two layers\n",
    "train_model_merge_mid.requires_grad_(False)\n",
    "train_model_merge_mid.layer1[0].requires_grad_(True)\n",
    "train_model_merge_mid.layer1[1].requires_grad_(True)\n",
    "epoch_loss_s = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007875407226569951\n",
      "0.0007164565998129547\n",
      "0.0007435208694636822\n",
      "0.0007602160020358861\n",
      "0.0006976782626286149\n",
      "0.0007211794837377965\n",
      "0.0007060918065719306\n",
      "0.0007507258039340377\n",
      "0.0006767478171177208\n",
      "0.000726337816286832\n",
      "Accuracy of the network on the test images: 92.260000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "92.26"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    total = 0\n",
    "    for data, _ in train_loader:\n",
    "        data = add_dimension(data, n_steps)\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs_s = [model.layer1[:2](data).mean(1) for model in model_merge_s]\n",
    "            outputs_avg = torch.zeros_like(outputs_s[0])\n",
    "            for outputs in outputs_s:\n",
    "                outputs_avg += outputs\n",
    "            outputs_avg /= len(outputs_s)\n",
    "            \n",
    "        outputs_mid = train_model_merge_mid.layer1[:2](data).mean(1)\n",
    "        loss = (outputs_mid - outputs_avg).abs().mean()\n",
    "        # print(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item() * data.size(0)\n",
    "        total += data.size(0)\n",
    "    print(epoch_loss / total)\n",
    "    epoch_loss_s.append(epoch_loss / total)\n",
    "validate_snn(train_model_merge_mid, test_loader, n_steps, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "activation matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 92.340000\n",
      "Accuracy of the network on the test images: 92.370000\n",
      "Accuracy of the network on the test images: 92.430000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "92.43"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_merge_1 = deepcopy(model_merge_s[0])\n",
    "model_merge_1.to(device)\n",
    "model_merge_2 = deepcopy(model_merge_s[1])\n",
    "model_merge_2.to(device)\n",
    "\n",
    "train_model_merge_mid = deepcopy(model_merge_mid)\n",
    "train_model_merge_mid.to(device)\n",
    "validate_snn(train_model_merge_mid, test_loader, n_steps, device)\n",
    "validate_snn(model_merge_1, test_loader, n_steps, device)\n",
    "validate_snn(model_merge_2, test_loader, n_steps, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "class OnlineMean:\n",
    "    def __init__(self, num_features, device=None):\n",
    "        self.sum = torch.zeros(num_features).to(device)\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, batch):\n",
    "        # batch shape: (batch_size, channels, width, height)\n",
    "        # or\n",
    "        # batch shape: (batch_size, num_features)\n",
    "        if len(batch.shape) == 4:\n",
    "            self.sum += torch.sum(batch, dim=(0, 2, 3))\n",
    "        elif len(batch.shape) == 2:\n",
    "            self.sum += torch.sum(batch, dim=0)\n",
    "        else:\n",
    "            raise ValueError(\"batch shape must be (batch_size, channels, \"\n",
    "                             \"width, height) or (batch_size, num_features)\")\n",
    "        self.count += batch.shape[0]\n",
    "\n",
    "    def mean(self):\n",
    "        return self.sum / self.count\n",
    "\n",
    "\n",
    "class OnlineCovariance:\n",
    "    def __init__(self, a_mean, b_mean, count, device=None):\n",
    "        assert a_mean.shape == b_mean.shape\n",
    "        d = a_mean.shape[0]\n",
    "        # ensure brodcast calculation\n",
    "        self.a_mean = torch.zeros_like(a_mean).double()\n",
    "        self.b_mean = torch.zeros_like(b_mean).double()\n",
    "        self.cov = torch.zeros((d, d)).to(device).double()\n",
    "        self.std_a = torch.zeros_like(a_mean).double()\n",
    "        self.std_b = torch.zeros_like(b_mean).double()\n",
    "        self.count = count\n",
    "\n",
    "    def update(self, a_batch, b_batch):\n",
    "        assert a_batch.shape == b_batch.shape\n",
    "        a_batch = a_batch.double()\n",
    "        b_batch = b_batch.double()\n",
    "        self.a_mean += a_batch.mean(dim=1) / self.count\n",
    "        self.b_mean += b_batch.mean(dim=1) / self.count\n",
    "        self.cov += torch.matmul(a_batch, b_batch.T) / a_batch.shape[1] / self.count\n",
    "        self.std_a += a_batch.std(dim=1) / self.count\n",
    "        self.std_b += b_batch.std(dim=1) / self.count\n",
    "\n",
    "    def pearson_correlation(self):\n",
    "        eps = 1e-4\n",
    "\n",
    "        self.cov = self.cov - torch.outer(self.a_mean, self.b_mean)\n",
    "        return torch.nan_to_num(self.cov / (torch.outer(self.std_a, self.std_b) + eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldL_s = []\n",
    "newL_s = []\n",
    "for L in range(1, 17):\n",
    "    model_merge_1.eval()\n",
    "    model_merge_2.eval()\n",
    "    dummy_input = train_loader.dataset[0][0].unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        dummy_input = add_dimension(dummy_input, n_steps)\n",
    "        dummy_out = model_merge_1(dummy_input, L=L, t=n_steps).mean(1)\n",
    "    num_channels = dummy_out.shape[1]\n",
    "    means_merge_1 = OnlineMean(num_channels, device)\n",
    "    means_merge_2 = OnlineMean(num_channels, device)\n",
    "    # run one epoch\n",
    "    num_batches = len(train_loader)\n",
    "    covs = OnlineCovariance(means_merge_1.mean(), means_merge_2.mean(), num_batches, device)\n",
    "    for data, _ in train_loader:\n",
    "        with torch.no_grad():\n",
    "            data = data.to(device)\n",
    "            data = add_dimension(data, n_steps)\n",
    "            # forward\n",
    "            acts_1 = model_merge_1(data, L=L, t=n_steps).mean(1)\n",
    "            acts_2 = model_merge_2(data, L=L, t=n_steps).mean(1)\n",
    "            # flatten activations: 'b c w h -> c (b h w)'\n",
    "            # or 'b c -> c b'\n",
    "            if len(acts_1.shape) == 4:\n",
    "                acts_1 = rearrange(acts_1, 'b c w h -> c (b h w)')\n",
    "                acts_2 = rearrange(acts_2, 'b c w h -> c (b h w)')\n",
    "            elif len(acts_1.shape) == 2:\n",
    "                acts_1 = rearrange(acts_1, 'b c -> c b')\n",
    "                acts_2 = rearrange(acts_2, 'b c -> c b')\n",
    "            covs.update(acts_1, acts_2)\n",
    "\n",
    "    # matching\n",
    "    perm_values = []\n",
    "    # calculate permutation\n",
    "    correlation = covs.pearson_correlation()\n",
    "    ri, ci = linear_sum_assignment(correlation.cpu().detach().numpy(),\n",
    "                                    maximize=True)\n",
    "    ci = torch.from_numpy(ci).to(device)\n",
    "    perm_values.append(ci)\n",
    "    oldL = torch.einsum('ij,ij->i', correlation,\n",
    "                        torch.eye(len(ci), device=device, dtype=torch.double)).sum()\n",
    "    newL = torch.einsum('ij,ij->i', correlation,\n",
    "                        torch.eye(len(ci), device=device, dtype=torch.double)[ci, :]).sum()\n",
    "    print(f\"L = {L}\")\n",
    "    print(f\"oldL: {oldL}\")\n",
    "    print(f\"newL: {newL}\")\n",
    "    print(f\"newL - oldL: {newL - oldL}\")\n",
    "    oldL_s.append(oldL)\n",
    "    newL_s.append(newL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L = 14\n",
      "oldL: 2312.218413115928\n",
      "newL: 2327.8608753852195\n",
      "newL - oldL: 15.642462269291627\n",
      "L = 15\n",
      "oldL: 2082.692316341654\n",
      "newL: 2087.361372362972\n",
      "newL - oldL: 4.669056021317829\n"
     ]
    }
   ],
   "source": [
    "perm_values = []\n",
    "\n",
    "for L in range(14, 16):\n",
    "    model_merge_1.eval()\n",
    "    model_merge_2.eval()\n",
    "    dummy_input = train_loader.dataset[0][0].unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        dummy_input = add_dimension(dummy_input, n_steps)\n",
    "        dummy_out = model_merge_1(dummy_input, L=L, t=n_steps).mean(1)\n",
    "    num_channels = dummy_out.shape[1]\n",
    "    means_merge_1 = OnlineMean(num_channels, device)\n",
    "    means_merge_2 = OnlineMean(num_channels, device)\n",
    "    # run one epoch\n",
    "    num_batches = len(train_loader)\n",
    "    covs = OnlineCovariance(means_merge_1.mean(), means_merge_2.mean(), num_batches, device)\n",
    "    for data, _ in train_loader:\n",
    "        with torch.no_grad():\n",
    "            data = data.to(device)\n",
    "            data = add_dimension(data, n_steps)\n",
    "            # forward\n",
    "            acts_1 = model_merge_1(data, L=L, t=n_steps).mean(1)\n",
    "            acts_2 = model_merge_2(data, L=L, t=n_steps).mean(1)\n",
    "            # flatten activations: 'b c w h -> c (b h w)'\n",
    "            # or 'b c -> c b'\n",
    "            if len(acts_1.shape) == 4:\n",
    "                acts_1 = rearrange(acts_1, 'b c w h -> c (b h w)')\n",
    "                acts_2 = rearrange(acts_2, 'b c w h -> c (b h w)')\n",
    "            elif len(acts_1.shape) == 2:\n",
    "                acts_1 = rearrange(acts_1, 'b c -> c b')\n",
    "                acts_2 = rearrange(acts_2, 'b c -> c b')\n",
    "            covs.update(acts_1, acts_2)\n",
    "\n",
    "    # matching\n",
    "    # calculate permutation\n",
    "    correlation = covs.pearson_correlation()\n",
    "    ri, ci = linear_sum_assignment(correlation.cpu().detach().numpy(),\n",
    "                                    maximize=True)\n",
    "    ci = torch.from_numpy(ci).to(device)\n",
    "    perm_values.append(ci)\n",
    "    oldL = torch.einsum('ij,ij->i', correlation,\n",
    "                        torch.eye(len(ci), device=device, dtype=torch.double)).sum()\n",
    "    newL = torch.einsum('ij,ij->i', correlation,\n",
    "                        torch.eye(len(ci), device=device, dtype=torch.double)[ci, :]).sum()\n",
    "    print(f\"L = {L}\")\n",
    "    print(f\"oldL: {oldL}\")\n",
    "    print(f\"newL: {newL}\")\n",
    "    print(f\"newL - oldL: {newL - oldL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_merge_2_am = deepcopy(model_merge_2)\n",
    "\n",
    "ci = perm_values[0]\n",
    "model_merge_2_am.classifier[1].layer.module.weight.data = model_merge_2_am.classifier[1].layer.module.weight.data[ci]\n",
    "model_merge_2_am.classifier[1].layer.module.bias.data = model_merge_2_am.classifier[1].layer.module.bias.data[ci]\n",
    "model_merge_2_am.classifier[4].layer.module.weight.data = torch.index_select(model_merge_2_am.classifier[4].layer.module.weight.data, 1, ci)\n",
    "\n",
    "ci = perm_values[0]\n",
    "model_merge_2_am.classifier[4].layer.module.weight.data = model_merge_2_am.classifier[4].layer.module.weight.data[ci]\n",
    "model_merge_2_am.classifier[4].layer.module.bias.data = model_merge_2_am.classifier[4].layer.module.bias.data[ci]\n",
    "model_merge_2_am.classifier[7].layer.module.weight.data = torch.index_select(model_merge_2_am.classifier[7].layer.module.weight.data, 1, ci)\n",
    "\n",
    "sd_merge_mid_am = interpolate_state_dicts(model_merge_1.state_dict(), model_merge_2_am.state_dict(), 0.5)\n",
    "model_merge_mid.load_state_dict(sd_merge_mid_am)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 92.240000\n",
      "Accuracy of the network on the test images: 91.990000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91.99"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_snn(model_merge_mid, test_loader, n_steps, device)\n",
    "reset_bn_stats(model_merge_mid, device, train_loader, n_steps, layerwise=False, ann=False, use_double=False)\n",
    "validate_snn(model_merge_mid, test_loader, n_steps, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
